{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fall 2018 wrap up\n",
    "\n",
    "files needed = ('stats_models_ols_finished.ipynb')\n",
    "\n",
    "Today's agenda:\n",
    "1. Python on your laptop\n",
    "2. Set up GitHub to host your work\n",
    "3. Reflect on class, discuss where to go from here\n",
    "4. Office hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminders\n",
    "\n",
    "1. Submit project files by 11:59 PM on Friday December, 14, 2018. Follow submission instructions in 'project information' document. \n",
    "2. Today is the last day to complete the course evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python on your laptop\n",
    "\n",
    "We have been lucky to have the sscc and winstat to use in class. Soon, you will be moving on from this class, and the University, so it makes sense to set up a local python installation. \n",
    "\n",
    "On winstat, we have been working with the Anaconda. If you recall from earlier in the semester, python is a standard set of functions and data types that can be extended by installing packages. Anaconda is a distribution: a bundle of python and a set of packages that are useful for data analysis and numerical computing. A list of the packages is [here](https://docs.anaconda.com/anaconda/packages/py3.7_win-64/). This includes many of the packages we have been using: numpy, pandas, matplotlib, seaborn, scikit-learn...\n",
    "\n",
    "Let's install Anaconda on our laptops. \n",
    "\n",
    "1. Go to [https://www.anaconda.com/download/](https://www.anaconda.com/download/) and click on the **python 3.7** download button.\n",
    "2. Follow the prompts. **FOR PC USERS**: When it asked,  check the box to 'add anaconda to the path.'\n",
    "3. Run jupyter notebook\n",
    "4. If all goes well, a web browser will open and jupyter notebook will be open to your user directory\n",
    "5. Open and run all cells in 'stats_models_ols_finished.ipynb'. This notebook uses many packages, so it is a good test that everything is up and running. \n",
    "\n",
    "If step 5 worked, then you are ready to code. I recommend that you move your files from winstat to your local machine at some point so you have a local copy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GitHub\n",
    "\n",
    "GitHub is a web-based service that hosts (stores) files. It implements a powerful *version control* system called Git and has other features like bug tracking, wikis, etc. \n",
    "\n",
    "There are a lot of useful things you can do with GitHub --- most of which is outside the scope of our class. If you continue on and venture deeper into developing code (particularly if you are doing it with others) you will want to learn more about these features. \n",
    "\n",
    "For our purpose, we want to take advantage of GitHub's ability to host jupyter notebooks. If you have ever clicked on the notebook links on the website, you know that a jupyter notebook is just a text file. The jupyter notebook software interprets the text file and renders what we see on the screen. When we upload our notebooks to GitHub, they will be rendered for others to see when they go to your GitHub repository. \n",
    "\n",
    "Let's set up GitHub. \n",
    "\n",
    "1. Go to [https://github.com/](https://github.com/) and create an account. If you already have a GitHub account, sign in.\n",
    "2. Once you are signed in, proceed to the repositories page. A repository is like a folder. \n",
    "3. Create a new repository. Name it something like 'Kim-Ruhl's-Portfolio'. Make it public and check the box to initialize with a readme file. \\[You can delete this repository later.\\]\n",
    "4. Edit the readme file to describe your repository. You can use markdown here. 'Commit' the changes. \n",
    "5. Upload an ipynb file to your repository. View the file!\n",
    "\n",
    "You can create as many repositories as you like. \n",
    "\n",
    "### Create a portfolio\n",
    "\n",
    "You now have a place you can upload your project and other work. Linking to the notebook on GitHub is an easy way to share your accomplishments with others: graduate schools, potential employers, your mom and dad...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where we have been...\n",
    "\n",
    "Let's take a minute to reflect on what you knew when you walked into class on September 5. On that day we looked at some graphics. How does your approach to these figures today differ from your approach three months ago?  \n",
    "\n",
    "### Voting in Wisconsin\n",
    "\n",
    "Go to [https://www.nytimes.com/elections/results/wisconsin](https://www.nytimes.com/elections/results/wisconsin) and focus on the presidential results\n",
    "\n",
    "\n",
    "### The employment situation\n",
    "Go to [https://projects.fivethirtyeight.com/jobs-day](https://projects.fivethirtyeight.com/jobs-day) and scroll down to the figure titled 'The unemployment rate' and the figures that follow. \n",
    "\n",
    "\\[It took me 10 minutes of googling 'stacked blocks pictures' just to figure out that the last figure is called a 'place value block'. I have not found anyone trying to make these in python. If you figure this out someday, let me know! I will be trying to make some of these figures over Christmas break.\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skills we have developed\n",
    "\n",
    "It's always a good idea to take a moment at the end of a class or project to take an inventory of what we have done or what skills we have learned. You will often be asked to make summaries like this on resumes and reports. Writing the summary when it is all fresh in your head is easier. \n",
    "\n",
    "Skills acquired\n",
    "\n",
    "1. Basic python programming: data types, loops, conditionals, functions\n",
    "2. Pandas proficiency: reading and saving data, working with DataFrames and Series (slicing, subsetting), indexing, using web apis\n",
    "3. Data cleaning and preparation: dealing with missing values, applying transformations to raw data, working with dates and times\n",
    "4. Data 'wrangling': reshaping data, merging data sets\n",
    "5. Basic analysis: summarizing data, using groupby to efficiently analyze subsets\n",
    "6. Formal analysis: linear regression, instrumental variables, autoregressive models, probit/logit\n",
    "7. Visualization: bar plots, time-series plots, line plots, scatter plots, maps\n",
    "\n",
    "You are probably more comfortable with some of these skills more than others. You can always go back and look through the jupyter notebooks to brush up. (I need to practice my reshaping more!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data we have explored\n",
    "\n",
    "Having experience with commonly-used datasets is valuable. Some datasets we have worked with this semester include:\n",
    "\n",
    "1. FRED. A repository of economic data hosted by the St. Louis Federal Reserve Bank.\n",
    "2. American fact finder. A portal into the U.S. Census data.  \n",
    "3. Census shape files. Census tracts, counties, and states. \n",
    "4. Zillow. Housing market data.\n",
    "5. Airline origin and destination survey (DB1B). Ticket prices and passenger itineraries.  \n",
    "6. College scorecard. University level data about students and outcomes. \n",
    "\n",
    "Links to these datasets can be found at [http://kimjruhl.com/data-analytics-resources](http://kimjruhl.com/data-analytics-resources.). \n",
    "\n",
    "Many you worked with and learned about other datasets for your projects. Add those data sets to the list above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go from here\n",
    "\n",
    "This class has (hopefully) provided you with a set of skills and a window into many different things you can do with a computer, python, and some data. Suppose you thought this course was fun, or useful, or both. Where could you go from here? The sky is the limit. You could spend the rest of your life learning about this kind of stuff, but here are some thoughts.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More coding\n",
    "We developed a pretty good understanding of how to *use* python. We did not spend much time learning how to 'code': Deeply understanding object oriented programming; structuring complex code; coding as part of a team; code optimization.\n",
    "\n",
    "To be honest, most data analysis does not require you to be an expert coder. Being a better programmer, though, is helpful. If you would like to learn more about writing code, a programming course could be a good idea. You could do this here at UW, at MATC, or as a self-guided program online or from a book.   \n",
    "\n",
    "**Some benefits**: Being a better coder means that you will likely write more efficient code, which becomes more important as the datasets get larger. You will also become better at writing reusable code, so that you save time and effort. It is also worth noting that once you have a good sense of how to program, learning a new language (R, Java, Ruby...) is much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More analytic tools\n",
    "We spent a lot of time learning how to wrangle data. Real-world data are messy, and must be beaten into shape before we can do anything useful with it. Our analytic tools were mostly lifted from the econometrics courses you have already taken. We learned how to implement them in python. \n",
    "\n",
    "If analytic tools interest you, think about picking up some more of them. The economics department offers a forecasting course (Econ 460, in the fall) and machine learning (Econ 690, in the fall). The internet is full of data analytic tutorials. Panel data? Simulation-based econometrics? Financial statistics? Think about what kinds of data you want to work with and what kinds of questions you want to ask. Then go find the tools. \n",
    "\n",
    "**Some benefits**: Having a broad set of skills will allow you to tackle a wide variety of questions. If you want to become an expert in a particular field, drill down into the techniques that are most applicable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data tools\n",
    "Our focus was on python, pandas, and matplotlib/seaborn/geopandas. Data is often locked away in databases that require structured query language (SQL) type interfaces. Learning some SQL will allow you to get at that data --- even if it is just so that you can download it and load it into pandas. \n",
    "\n",
    "Learning how to read and write javascript object notation (JSON) encoded data will make it easier to snag data from the web. You can do this in pandas. Grab a cup of coffee and google 'jason pandas tutorial.' \n",
    "\n",
    "'Big data' tools like [Hadoop](https://hadoop.apache.org/) are aimed at working with really large datasets distributed across a cluster of computers. This is a pretty advanced skill, but there is no reason to think you couldn't learn how to use it if you put in the effort. \n",
    "\n",
    "**Some benefits**: The more types of data you can access, the more you can do."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
